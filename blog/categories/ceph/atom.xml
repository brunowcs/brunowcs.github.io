<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ceph | brunocarvalho.net]]></title>
  <link href="http://brunocarvalho.net/blog/categories/ceph/atom.xml" rel="self"/>
  <link href="http://brunocarvalho.net/"/>
  <updated>2018-09-19T14:12:05-03:00</updated>
  <id>http://brunocarvalho.net/</id>
  <author>
    <name><![CDATA[Bruno Carvalho]]></name>
    <email><![CDATA[brunowcs@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Métricas de Latência no CEPH]]></title>
    <link href="http://brunocarvalho.net/blog/2018/09/18/metricas-de-latencia-no-ceph/"/>
    <updated>2018-09-18T16:42:11-03:00</updated>
    <id>http://brunocarvalho.net/blog/2018/09/18/metricas-de-latencia-no-ceph</id>
    <content type="html"><![CDATA[<p><span style="display:block;text-align:center"><img src="/images/ceph/ceph-metrica-logo.png" alt="" /></span></p>

<p>Neste post compartilharei um dashboard em grafana com métricas de latência criado para telegraf com influxdb, visto que pesquisando na internet não achei nada sobre latência para este plugin e não era à toa, pois só na versão Lumiuous foi possível corrigir &ldquo;admin socket permission&rdquo; então resolvi criar um do zero e compartilhando com a comunidade, explicando como utilizar tanto no jewel quanto no luminous.</p>

<blockquote><p>Não irei abordar instalação do influxdb, grafana e telegraf pois tem muita coisa na internet, apenas os pontos principais para o dashboard funcionar.</p></blockquote>

<p>Com o comando abaixo é possível verificar media  latência do commit e apply do Ceph</p>

<pre><code># ceph osd perf

commit_latency(ms) apply_latency(ms)
............... ......................
</code></pre>

<p>Comentarei os 4 mais importantes:</p>

<p>A gravação do objeto em um cluster com replica de 3 gastará 6 IOs para se concluido por conta da gravação  journal(O_DIRECT) e do disco efetivamente. Na maioria das vezes veremos mais IOPS de write por conta das suboperações do ceph de replicação, diferente do read que só faz leitura na OSD primaria.</p>

<ul>
<li><strong>ops</strong> - Operações por segundo nas OSDs.</li>
<li><strong>Journal_latency</strong> - Tempo que leva para gravar no journal, ou seja, tempo de ack do write para o cliente.(O_DIRECT e O_DSYNC)</li>
<li><strong>apply_latency</strong> - Tempo de latência até a transação termina, ou seja, o tempo de gravação + journal.</li>
<li><strong>commit_latency</strong> - Tempo que leva para realizar o syncfs() após a expiração do filestore_max_sync_interval, no caso a descida do journal para o disco.</li>
</ul>


<p>As métricas acima são as que nos dão uma media de como anda a latência do nosso cluster, o dashboard abaixo irá apresentar no grafana essas informações entre outras.</p>

<p>Por padrão algumas métricas de subsystem do cluster Ceph já vem ativo, outras teremos que ativar no ceph.conf ou via OSDs com inject. Verifique se seu cluster está com os perfs true.</p>

<pre><code># ceph --admin-daemon /var/run/ceph/ceph-osd.26.asok  config show | grep perf
"debug_perfcounter": "0\/0",
"perf": "true",
"mutex_perf_counter": "true",
"throttler_perf_counter": "true",
</code></pre>

<p>Crie o arquivo abaixo e não esqueça de adicionar as tags para facilitar a seleção no grafana entre SATA e SSD ou escolha uma tag de sua preferência.</p>

<pre><code class="bash"># cat /etc/telegraf/telegraf.d/ceph.conf
[[inputs.ceph]]
  ## This is the recommended interval to poll.  Too frequent and you will lose
  ## data points due to timeouts during rebalancing and recovery
  interval = '1m'
  tags = "storage,osd,ssd"
  ## All configuration values are optional, defaults are shown below

  ## location of ceph binary
  ceph_binary = "/usr/bin/ceph"

  ## directory in which to look for socket files
  socket_dir = "/var/run/ceph"

  ## prefix of MON and OSD socket files, used to determine socket type
  #mon_prefix = "ceph-mon"
  osd_prefix = "ceph-osd"

  ## suffix used to identify socket files
  socket_suffix = "asok"

  ## Ceph user to authenticate as, ceph will search for the corresponding keyring
  ## e.g. client.admin.keyring in /etc/ceph, or the explicit path defined in the
  ## client section of ceph.conf for example:
  ##
  ##     [client.telegraf]
  ##         keyring = /etc/ceph/client.telegraf.keyring
  ##
  ## Consult the ceph documentation for more detail on keyring generation.
  #ceph_user = "client.telegraf"

  ## Ceph configuration to use to locate the cluster
  #ceph_config = "/etc/ceph/ceph.conf"

  ## Whether to gather statistics via the admin socket
  gather_admin_socket_stats = true

  ## Whether to gather statistics via ceph commands, requires ceph_user and ceph_config
  ## to be specified
  #gather_cluster_stats = true
</code></pre>

<p>Será nescessario adicionar o usuario telegraf no grupo ceph para que ele possa ler os sockets do /var/run/ceph</p>

<pre><code># addgroup telegraf ceph
</code></pre>

<p><strong>ATENÇÃO:</strong> Aqui está o pulo do gato, nas versões anteriores ao Ceph 12.0.3 Luminous, terá que executar o seguinte comando abaixo</p>

<pre><code># chmod  g+w /var/run/ceph/*
</code></pre>

<p>Esse comando contorna o problema &ldquo;admin socket permission&rdquo; que foi corrigido nas versões acima da 12.0.3</p>

<blockquote><p>common: common/admin_socket: add config for admin socket permission bits (pr#11684, runsisi)
<a href="https://github.com/ceph/ceph/pull/11684">https://github.com/ceph/ceph/pull/11684</a></p></blockquote>

<p>Se a OSD for reiniciada a permissão se perder, se estiver abaixo da 12.0.3, recomendo adicionar a permissão no systemd após o startup da OSD. Se já estiver na versão superior basta adicionar no ceph.conf a config abaixo</p>

<pre><code>admin_socket_mode 0775
</code></pre>

<p>Reiniciei o telegraf</p>

<pre><code>systemctl restart telegraf 
</code></pre>

<p>Verifique se não está ocorrendo nenhum error de socket no syslog</p>

<pre><code>telegraf[986875]: 2018-09-18T21:49:03Z E! error reading from socket '/var/run/ceph/ceph-osd.51.asok': error running ceph dump: exit status 22
</code></pre>

<p>Teste se o telegraf está coletando as metricas do seu servidor de OSD com a permissão do telegraf</p>

<pre><code># sudo -u telegraf telegraf --debug -test -config /etc/telegraf/telegraf.conf -config-directory /etc/telegraf/telegraf.d  -input-filter ceph

# sudo -u telegraf ceph --admin-daemon /var/run/ceph/ceph-osd.14.asok perf dump
</code></pre>

<p>Se tudo estiver ok, basta importa o dashboard para seu grafana e ser feliz! :)</p>

<p>Dashboard Telegraf Ceph - Latency: <a href="https://grafana.com/dashboards/7995">https://grafana.com/dashboards/7995</a></p>

<p>Plugin Utilizado: <a href="https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ceph">https://github.com/influxdata/telegraf/tree/master/plugins/inputs/ceph</a></p>

<p><span style="display:block;text-align:center"><img src="/images/ceph/ceph-latencia.PNG" alt="" /> </span>
<span style="display:block;text-align:center"><img src="/images/ceph/ceph-grafico.PNG" alt="" /> </span></p>

<p>Referências de métricas:</p>

<p><a href="https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/3/html/administration_guide/performance_counters">https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/3/html/administration_guide/performance_counters</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Resolvendo PGs inconsistent no CEPH manualmente]]></title>
    <link href="http://brunocarvalho.net/blog/2018/09/12/resolvendo-pgs-inconsistent-no-ceph-manualmente/"/>
    <updated>2018-09-12T15:23:02-03:00</updated>
    <id>http://brunocarvalho.net/blog/2018/09/12/resolvendo-pgs-inconsistent-no-ceph-manualmente</id>
    <content type="html"><![CDATA[<p><span style="display:block;text-align:center"><img src="/images/ceph/ceph-manu.png" alt="" /> </span></p>

<p>Recentemente eu tive um problema de badblock em um dos discos que gerou uma inconsistent na PG e o cluster não conseguiu se resolver automaticamente, mesmo tirando o disco defeituoso do cluster e parando a OSD associada.</p>

<p>As soluções abaixo me ajudaram a resolver meu problema que se estendeu por alguns dias. Caso tenha suporte recomendo abrir um chamado ou faça por sua conta e risco.</p>

<p>A solução 1 resolver a maioria dos casos e no meu caso não houver impacto nem downtime.</p>

<p>Problema ocorreu no Ubuntu 16.4 com Jewel utilizando FileStore replica de 3.</p>

<p>Antes de iniciar recomendo a leitura do meu post <a href="http://brunocarvalho.net/blog/2018/09/11/ceph-scrubbing/">&ldquo;Ceph Scrubbing&rdquo;</a> será fundamental você entender esse cara antes de começar.</p>

<p>1 - Buscando pgs inconsistente no nosso caso &ldquo;5.163&rdquo;</p>

<pre><code># ceph health detail  | grep inconsistent
HEALTH_ERR 
pg 5.163 is active+remapped+inconsistent+wait_backfill, acting [26,45,135]
</code></pre>

<blockquote><p>Podemos ver que apresentou também em quais OSDs estão essas pgs [26,45,135] execute o comando abaixo para descobrir em quais servidores estão as OSDs</p></blockquote>

<pre><code>root@serv-117:/home/bruno.carvalho# ceph osd find 26
{   
    "osd": 16,
    "ip": "10.0.0.14:6842\/21992",
    "crush_location": {
        "host": "stor-121",
        "rack": "sata",
        "root": "default"
    }
}
root@serv-117:/home/bruno.carvalho# ceph osd find 45
{
    "osd": 91,
    "ip": "10.0.0.15:6814\/8362",
    "crush_location": {
        "host": "stor-122",
        "rack": "sata",
        "root": "default"
    }
}
root@serv-117:/home/bruno.carvalho# ceph osd find 135
{
    "osd": 30,
    "ip": "10.0.0.17:6812\/10485",
    "crush_location": {
        "host": "stor-124",
        "rack": "sata",
        "root": "default"
    }
}
</code></pre>

<p>2 - Logue no servidor da OSD primaria e busque o objeto problemático, se objeto problemático estiver na primaria não esqueça de descer com primary-affinity.()</p>

<pre><code># grep -Hn 'ERR' /var/log/ceph/ceph-osd.26.log (apresentar uma tripa de erro, o importante será o nome do objeto )
..... log [ERR] : 5.163 .... 
udata.3b2ab5c0fdd3f.00000000000059d2__head_892078F9__4
.....
</code></pre>

<p>No Monitor podemos buscar com o comando abaixo (apresenta um json grande, porem o importante é o nome do objeto, algo parecido com nome do comando acima.)</p>

<pre><code># rados list-inconsistent-obj 5.163--format=json-pretty
</code></pre>

<p>Se nescessário jogue a OSD primário para outra OSD.</p>

<pre><code># ceph osd primary-affinity 26 0
</code></pre>

<p>3 - Logue nos servidores das 3 OSDs, busque o arquivo e verifique o md5 do objeto, seu tamanho e identifique o que está diferente entre os 3, no caso o objeto diferente será o que você irar remover para mandar o cluster se recuperar.</p>

<pre><code># find /var/lib/ceph/osd/ceph-26/current/5.163_head/ -name '*00000000000059d2*' -ls
...
/var/lib/ceph/osd/ceph-26/current/5.163_head/rbd\\udata.3b2ab5c0fdd3f.00000000000059d2__head_892078F9__4
# md5sum /var/lib/ceph/osd/ceph-26/current/5.163_head/rbd\\udata.3b2ab5c0fdd3f.00000000000059d2__head_892078F9__4\
d12a1f042f2a98a79943c990d3a5b2c8  /var/lib/ceph/osd/ceph-26/current/5.163_head/rbd\\udata.3b2ab5c0fdd3f.00000000000059d2__head_892078F9__4
</code></pre>

<p>4 - Set noout no cluster</p>

<pre><code># ceph osd set noout
</code></pre>

<p>5 - Pare a OSD</p>

<pre><code># systemctl stop ceph-osd@26
</code></pre>

<p>6 - Execute o flush do journal</p>

<pre><code># ceph-osd -i 26 --flush-journal
SG_IO: bad/missing sense data, sb[]:  70 00 05 00 00 00 00 0a 00 00 00 00 20 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
SG_IO: bad/missing sense data, sb[]:  70 00 05 00 00 00 00 0a 00 00 00 00 20 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
2018-08-23 18:31:57.691076 7f69269888c0 -1 flushed journal /var/lib/ceph/osd/ceph-26/journal for object store /var/lib/ceph/osd/ceph-26
</code></pre>

<p>7 - Remova o Objecto com problema</p>

<pre><code># rm  -rf /var/lib/ceph/osd/ceph-26/current/5.163_head/rbd\\udata.3b2ab5c0fdd3f.00000000000059d2__head_892078F9__4
</code></pre>

<p>8 - Corrigindo permissão da OSD</p>

<pre><code># chown ceph:ceph -R /var/lib/ceph/osd/ceph-26/current/omap/
</code></pre>

<p>9 - Subindo OSD</p>

<pre><code># systemctl start ceph-osd@26
</code></pre>

<p>10 - Tira o noout no cluster e aguarde o cluster ficar com apenas a pg inconsistent</p>

<pre><code># ceph osd unset noout
</code></pre>

<p>11 - Vamos agora executar um repair para corrigir o problema.</p>

<pre><code># ceph pg repair 5.163
</code></pre>

<blockquote><p>Agora veja o log da OSD primaria.</p></blockquote>

<pre><code># tail -f /var/log/ceph/ceph-osd.26.log

2018-08-23 18:33:30.568207 7fc1ee195700 -1 log_channel(cluster) log [ERR] : 5.163 shard 26 missing 5:9f1e0491:::rbd_data.3b2ab5c0fdd3f.00000000000059d2:head
2018-08-23 18:33:30.568212 7fc1ee195700  0 log_channel(cluster) do_log log to syslog
2018-08-23 18:33:36.274075 7fc1ee195700 -1 log_channel(cluster) log [ERR] : 5.163 repair 1 missing, 0 inconsistent objects
2018-08-23 18:33:36.274079 7fc1ee195700  0 log_channel(cluster) do_log log to syslog    
2018-08-23 18:33:36.274142 7fc1ee195700 -1 log_channel(cluster) log [ERR] : 5.163 repair 1 errors, 1 fixed
2018-08-23 18:33:36.274144 7fc1ee195700  0 log_channel(cluster) do_log log to syslog
</code></pre>

<p>No log acima podemos ver &ldquo;log [ERR] : 5.163 repair 1 errors, 1 fixed&rdquo; isso mostra que ele encontrou o objecto que faltava e corrigiu criando novamente a replica.</p>

<h2>Solução 2</h2>

<p> Identificar e remover o objeto problemático na OSD excluindo com ceph-object-tools executando com deep-scrub</p>

<p>Com o objeto problemático já identificado, execute os procedimentos: 4, 5 e 6 após sigar os procedimentos abaixo</p>

<p>1 - Com a OSD down localize o objeto</p>

<pre><code># ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-26 --journal /var/lib/ceph/osd/ceph-26/journal --pgid 5.163 --op list | grep rbd_data.3b2ab5c0fdd3f.00000000000059d2
["5.163",{"oid":"rbd_data.3b2ab5c0fdd3f.00000000000059d2","key":"","snapid":-2,"hash":3828189539,"max":0,"pool":5,"namespace":"","max":0}]
</code></pre>

<p>2 - Removendo Objeto.</p>

<pre><code># ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-26 --journal /var/lib/ceph/osd/ceph-26/journal --pgid 5.163 '{"oid":"rbd_data.3b2ab5c0fdd3f.00000000000059d","key":"","snapid":-2,"hash":3828189539,"max":0,"pool":5,"namespace":"","max":0}' remove
remove #5:c691b427:::rbd_data.3b2ab5c0fdd3f.00000000000059d2:head#
</code></pre>

<p>3 - Corrigir permissão</p>

<pre><code># chown -R ceph:ceph /var/lib/ceph/osd/ceph-135/current/omap/
</code></pre>

<p>4 - Iniciar OSD</p>

<pre><code># systemctl start ceph-osd@26
</code></pre>

<p>5 - Execute o deep-scrub na pg (Veja artigo do &ldquo;Ceph Scrubbing&rdquo;, para execução com espaço de tempo menor)</p>

<pre><code># ceph pg deep-scrub 5.163
</code></pre>

<p>O deep-scrub no CEPH é um processo que passa em todas OSDs para verificar inconsitencia dos dados e corrigir eventuais problemas,  podemos comparar ao fsck. Dependendo das configurações do seu Cluster o deep-scrub não executará imediatamente, verifique no log da OSD primaria ou execute o seguinte comando query pg e veja data da ultima vez que ele passou.</p>

<p>Se o deep-scrub não for executado, verifique as configurações de osd_scrub_max_interval, também é importante verificar o osd_scrub_load_threshold, pois se sua CPU estiver e um certo limite o deep-scrub não rodará.</p>

<p>Leia mais sobre: <a href="http://brunocarvalho.net/blog/2018/09/11/ceph-scrubbing/">&ldquo;Ceph Scrubbing&rdquo;</a></p>

<p>6 - Query pg</p>

<pre><code>#  ceph pg 5.163 query 
..................
        "last_deep_scrub_stamp": "2018-08-23 15:48:42.107928",
..................   
</code></pre>

<p>Também podemos verificar logo no final do comando query o deep-scrub sendo executado na PG.</p>

<pre><code>"scrub": {
            "scrubber.epoch_start": "57000",
            "scrubber.active": 1,
            "scrubber.state": "WAIT_REPLICAS",
            "scrubber.start": "5:578cfc17:::rbd_data.57e3dd6b7d297f.000000000000b063:0",
            "scrubber.end": "5:578cff8c:::rbd_data.552a0c53cb890c.00000000000046aa:0",
            "scrubber.subset_last_update": "58460'37642760",
            "scrubber.deep": true,
            "scrubber.seed": 4294967295,
            "scrubber.waiting_on": 1,
            "scrubber.waiting_on_whom": [
                "48"
</code></pre>

<p>Após o termino do deep-scrub provavelmente sua pg já estará OK.</p>

<p>Nos próximos posts irei apresentar:</p>

<ul>
<li><strong>Métricas de Latência no Ceph</strong> - Falarei sobre Telegraf/Influx/Grafana um dashboard pronto com metricas avançadas de latency/journal/queue/iops/throughput que te ajudaram a ajustar melhor as configurações do seu cluster)</li>
<li><strong>Melhores práticas com Ceph</strong> - Desde o Hardware, S.O e configurações do ceph.conf para você obter melhor performance do seu cluster.</li>
</ul>


<p>Referência: <a href="http://lists.ceph.com/pipermail/ceph-users-ceph.com/">http://lists.ceph.com/pipermail/ceph-users-ceph.com/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ceph Scrubbing]]></title>
    <link href="http://brunocarvalho.net/blog/2018/09/11/ceph-scrubbing/"/>
    <updated>2018-09-11T19:03:07-03:00</updated>
    <id>http://brunocarvalho.net/blog/2018/09/11/ceph-scrubbing</id>
    <content type="html"><![CDATA[<p><span style="display:block;text-align:center"><img src="/images/ceph/ceph.png" alt="" /> </span></p>

<p>Olá turmadaaa, um pouco sumido, mas estou de volta com grandes novidades. A pouco mais de 2 anos realizei a implantação de 4 Cluster Ceph com Juju e MaaS na america latina que hoje tem quase 8 Petabyte raw, e quanto mais o cluster cresce, mais ajustes e problemas diferentes aparecem.</p>

<p>Recentemente encontrei um bug relacionado a recuperação de “Placement groups(PGs)” dentro do Jewel. O Ceph não estava conseguindo resolver a inconsistência de uma PG, mesmo executando o “ceph repair” e forçando a passagem do Scrubbing. Pelo que notei nos últimos lançamentos do CEPH tem alguns bug fix sobre o assunto.</p>

<p>Bem este será o primeiro de alguns posts mais avançado que irei falar de como resolver manualmente uma pg inconsistente, mas neste momento vamos entender melhor o Scrubbing no Ceph</p>

<p>Podemos comparar o Scrubbing do Ceph com o fsck para o armazenamento de objetos dentro do Cluster.
Ao executar “ceph -s” nas ultimas linhas veremos as “placement groups(PGs)” que estão como “active+clean”, que significa que estão oks.</p>

<p>Para cada placement groups(PGs) o Ceph gera um catálogo de todos os objetos e compara cada objeto primário e suas réplicas garantindo assim que nenhum objeto esteja ausente ou seja incompatível. Muitas vezes vamos achar a seguinte informação “1 active+clean+inconsistent” isso nos mostrar que alguma replicar dentro do cluster está inconsistente. Como o Ceph realizado seu auto reconvery esse problema é resolvido automaticamente na passagem do scrub, porem recentemente percebi que isso não é uma verdade absoluta se você não tiver um ambiente bem configurado.</p>

<p>A passagem do Scrubbing é penosa para o cluster e muitas vezes só passará quando o sistema estiver com uma carga menor ou se as configurações forem alteradas via inject nas “OSDs”. Veja as 3 formas que podemos verificar as configurações no cluster e como podemos alterar a quente e força uma passagem imediata do scrub.</p>

<p><strong>Verificando configurações no Ceph:</strong></p>

<p>Apresenta apenas as configurações default do ceph</p>

<pre><code># ceph --show-config | grep osd_scrub_load_threshold
</code></pre>

<p>Apresenta a configuração permanente do ceph.conf</p>

<pre><code># ceph -n osd.X --show-config | grep osd_scrub_load_threshold
</code></pre>

<p>Apresentar a configuração atual</p>

<pre><code># ceph --admin-daemon /var/run/ceph/ceph-osd.21.asok config show | grep osd_scrub_load_threshold
</code></pre>

<p>Alterando Configuração a quente</p>

<pre><code># ceph tell osd.X injectargs '--osd_scrub_load_threshold 0.5' 
</code></pre>

<p>O Scrubbing é muito importante para manter a integridade dos dados, mas poderá reduzir o desempenho do seu cluster, como &ldquo;requests are blocked&rdquo; se não for realizado ajustes nas configurações baseado na carga do seu cluster.</p>

<p>Existe dois tipos de Scrubbing, um e o “Light scrubbing”, ele verifica o tamanho e os atributos do objeto e por default passa todos os dias e não sobrecarrega tanto o cluster. O “deep-scrubbing”  e uma limpeza mais profunda, lê os dados e usa somas de verificação para garantir a integridade, esse Scrubbing passa no decorrer da semana e gera uma carga maior no cluster. Como o “ceph -s“ conseguimos verificar em quantas “PGs” está sendo executado scrubbing no momento.</p>

<blockquote><p>26 active+clean+scrubbing+deep
7 active+clean+scrubbing</p></blockquote>

<p>Executando o comando abaixo, você consegue ver quando passou o último scrub/deep-scrub na PG</p>

<pre><code># Ceph osd PG_ID query 
..................
            "last_deep_scrub_stamp": "2018-08-23 15:48:42.107928",
..................   
</code></pre>

<p>Algumas configurações que devemos nos atentar para ajustar:</p>

<ul>
<li>osd_scrub_min_interval</li>
<li>osd_scrub_max_interval</li>
<li>osd_scrub_load_threshold</li>
<li>osd_max_scrubs</li>
<li>osd_deep_scrub_interval</li>
<li>osd_scrub_interval_randomize_ratio</li>
<li>osd_scrub_during_recovery</li>
</ul>


<p>Os Scrubbing começam após osd_scrub_min_interval desda ultima passagem, isso só ocorre se a CPU estiver abaixo do osd_scrub_load_threshold ou após osd_scrub_max_interval mesmo se o sistema estiver sobrecarregado.</p>

<p>Podemos também configurar um intervalo na madrugada para o Scrubbing passar osd_scrub_begin_hour/osd_scrub_end_hour. Com lançamento do Mimic, temos mais duas opções de intervalos osd_scrub_begin_week_day/osd_scrub_end_week_day</p>

<p>Quando executamos um ceph pg repair, ou um ceph pg deep-scrub ele não irá executar imediatamente e sim enviará um pedido a pg “instructing pg ID on osd.X to repair” porem precisa satisfazer as regras configuradas, veja a nota da documentação oficial abaixo.</p>

<blockquote><p>Nota: “Ceph will not scrub when the system load (as defined by getloadavg() / number of onlinecpus) is higher than this number. Default is 0.5.”</p></blockquote>

<p>A passagem deep-scrub não necessariamente depende do load_threshold, veja a nota abaixo.</p>

<blockquote><p>Nota: “The interval for “deep” scrubbing (fully reading all data). The osd scrub load threshold does not affect this setting.”</p></blockquote>

<p>Atenção as frags noscrub e nodeep-scrub definida no cluster e nas pools, caso esteja setada o scrub não será executado.</p>

<p>Creio que com essas informações já conseguimos manipular melhor os Scrubbing no cluster, que e essencial para a consistência das  “Placement groups(PGs)” e da performance do cluster. Nos próximos posts vamos entrar mais a fundo na manipulação manual do objeto e na sua recuperação.</p>

<p> Caso tenha alguma dúvida sobre o funcionamento do Ceph não deixa de assitir meu Webinar que postei aqui no Blog <a href="http://brunocarvalho.net/blog/2018/04/03/webinar-explorando-o-ceph/">Explorando o Ceph</a> Como tiveram várias dúvidas sobre o Webinar, lançarei uma série de artigos mais básicos com informações essencias para você ir “Explorando o Ceph”.</p>

<p>Nos próximo posts irei apresentar:</p>

<p><a href="http://brunocarvalho.net/blog/2018/09/12/resolvendo-pgs-inconsistent-no-ceph-manualmente/"> - Resolvendo PGs inconsistent no CEPH manualmente </a></p>

<p>Referência: <a href="http://docs.ceph.com/docs/master/rados/configuration/osd-config-ref/">http://docs.ceph.com/docs/master/rados/configuration/osd-config-ref/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Webinar Explorando o Ceph]]></title>
    <link href="http://brunocarvalho.net/blog/2018/04/03/webinar-explorando-o-ceph/"/>
    <updated>2018-04-03T14:27:42-03:00</updated>
    <id>http://brunocarvalho.net/blog/2018/04/03/webinar-explorando-o-ceph</id>
    <content type="html"><![CDATA[<p><img src="/images/ceph/webinartivit.jpg" alt="" /></p>

<p>A Internet das Coisas e a Terceira Plataforma Computacional estão levando as pessoas e as máquinas a gerarem milhões de dados digitais a cada instante. O volume de informações criadas no mundo, a médio e longo prazo, é infinito. Pesquisa da IBM mostra que, até 2020, o volume de dados previsto é de 40 zetabytes, ou seja, haverá quatro vezes mais dados digitais do que todos os grãos de areia existentes no planeta.  As máquinas irão gerar 42% de todo volume de dados e haverá mais de 200 bilhões de dispositivos conectados no mundo.</p>

<p>O crescimento desenfreado de dados e as constantes mudanças exige das empresas respostas rápidas para os negócios. A expansão dos dispositivos móveis aumentou o uso das redes sociais e também de dados. As companhias precisam de tecnologias para tratar dados com estratégias de Big Data e gerar mais serviços online para o mundo conectado.</p>

<p>Atualmente as empresas precisam ter serviços disponíveis 24 horas, a Cloud Computing abraça todas as aplicações criadas para abastecer o mundo conectado, tanto para o mercado corporativo quando para atender o consumidor final. Para que isso gere menos custo e valor para empresas precisamos de um mundo com soluções hiperconvergentes, e sem um storage eficiente e escalável baseado em Software Defined isso se tornaria inviável para muitas empresas e startups.</p>

<p>No Webinar “Explorando Ceph” que será realizado pela TIVIT na próxima quarta-feira dia 4, falarei um pouco mais sobre o storage que está revolucionando o mercado de Software Defined, será totalmente gratuito e online. Inscreva-se: <a href="http://go.tivit.com/webinar-explorando-ceph">Aqui</a></p>

<p><strong>GRAVAÇÃO:</strong></p>

<iframe width="100%" height="350px" src="https://www.youtube.com/embed/DayGJbPtB04" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Um pouco sobre o Ceph Day SP 2017]]></title>
    <link href="http://brunocarvalho.net/blog/2017/10/27/um-pouco-sobre-o-ceph-day-sp-2017/"/>
    <updated>2017-10-27T11:09:02-03:00</updated>
    <id>http://brunocarvalho.net/blog/2017/10/27/um-pouco-sobre-o-ceph-day-sp-2017</id>
    <content type="html"><![CDATA[<p><img src="/images/ceph/cephday0.png" alt="" /></p>

<p>Na última Quarta-feira(25/10) rolou o primeiro Ceph Day SP e o primeiro na América Latina organizado e realizado pelo nosso Manager Comunity Leonado Vaz e nosso amigo da Savant Marcos Sungaila, além de grandes patrocinadores como RedHat, Canonical, Suse entre outros&hellip;</p>

<p>Para quem não teve a oportunidade de estar presente perdeu um grande dia. Discutimos sobre a nova versão do Ceph, custos x performance, implementações, cases e principalmente o futuro do SDS</p>

<p><img src="/images/ceph/cephday1.png" alt="" /></p>

<p>A chegada da nova versão Luminous LTS que já é uma realidade, virou um divisor de águas no mundo do Software Define Storage(SDS) com várias melhorias como o novo backend BlueStorage que leva o Ceph a um nível de performance 2x mais rápido eliminando a camada do filesystem, além de grandes melhorias em toda sua estrutura.</p>

<p>Precisando de baixa latência e alta performance? O Ceph te entrega, tivemos uma palestra da Intel, uma das grandes colaboradoras do código, falando sobre Ceph com All-Flash.</p>

<p><a href="https://software.intel.com/en-us/articles/using-intel-optane-and-intel-3d-nand-technology-with-ceph-to-build-high-performance-cloud">SSDs to Build High-Performance Cloud Storage Solutions</a></p>

<p>Para os amantes do Zabbix como eu, o novo serviço de gerenciamento do Ceph(ceph-mgr) foi ampliado com vários módulos python, um deles exporta o status geral do cluster para o Zabbix habilitando o modulo no Ceph e configurando o template no zabbix.</p>

<pre><code class="bash">$ ceph zabbix config-set zabbix_host zabbix-server.local
$ ceph zabbix config-set identifier ceph.local
</code></pre>

<p>Para os amantes da interface GUI. Agora será possível ter um dashboard no Ceph de forma simples.</p>

<pre><code class="bash">$ ceph mgr module enable dashboard
</code></pre>

<p>Acesse <a href="http://you_active_mgr_host:7000/">http://you_active_mgr_host:7000/</a></p>

<p><img src="/images/ceph/cephday2.png" alt="" />
<img src="/images/ceph/cephday3.png" alt="" /></p>

<p>Outra grande novidade, agora já é possível fazer Erasure Coding tanto em RBD quanto em CephFS, que antes só era possível com object. Na mudança para o BlueStorage será possível suporta compressão de dados, trazendo mais economia no armazenamento.</p>

<p>E tem muito mais vindo por ai! Eu particularmente estou ansioso para o tão esperado QoS que está por vir na próxima versão ou dedup que será excelente para galera de backup. Aguardem que isso será só o começo da evolução que o Ceph vem trazendo para o mundo do Software Define Storage.</p>

<p>Referências:</p>

<p><a href="http://ceph.com/releases/v12-2-0-luminous-released/">http://ceph.com/releases/v12-2-0-luminous-released/</a></p>

<p><a href="http://ceph.com/community/new-luminous-dashboard/">http://ceph.com/community/new-luminous-dashboard/</a></p>

<p><a href="http://ceph.com/community/new-luminous-zabbix/">http://ceph.com/community/new-luminous-zabbix/</a></p>
]]></content>
  </entry>
  
</feed>
